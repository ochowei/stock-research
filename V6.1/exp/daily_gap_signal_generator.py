import os
import sys
import json
import time
import logging
import joblib
import warnings
from datetime import datetime, timedelta

import pandas as pd
import numpy as np
import yfinance as yf
import pandas_ta as ta
import xgboost as xgb
from pandas.tseries.holiday import USFederalHolidayCalendar
from pandas.tseries.offsets import CustomBusinessDay

# æŠ‘åˆ¶è­¦å‘Šèˆ‡éé—œéµæ—¥èªŒ
warnings.filterwarnings('ignore')
logging.getLogger('yfinance').setLevel(logging.CRITICAL)

# --- 1. å…¨åŸŸè¨­å®š (Configuration) ---

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
RESOURCE_DIR = os.path.join(BASE_DIR, '..', 'resource')
OUTPUT_DIR = os.path.join(BASE_DIR, 'output')
MODEL_PATH = os.path.join(OUTPUT_DIR, 'exp_07_model.joblib')

os.makedirs(OUTPUT_DIR, exist_ok=True)

# æª”æ¡ˆè·¯å¾‘
FILES = {
    'ASSET': '2025_final_asset_pool.json',
    'TOXIC': '2025_final_toxic_asset_pool.json',
    'CRYPTO': '2025_final_crypto_sensitive_pool.json',
    'HOLDING': '2025_holding_asset_pool.json'
}

# ç­–ç•¥åƒæ•¸
GAP_THRESHOLD = 0.005      # 0.5% (åŸºç¤é–€æª»)
PROFIT_THRESHOLD = 0.002   # 0.2% (AI è¨“ç·´ç›®æ¨™)
AI_CONFIDENCE_LV = 0.50    # AI é æ¸¬æ©Ÿç‡é–€æª» (å¤§æ–¼æ­¤å€¼æ‰ç®— GO)

# ä¸‹è¼‰è¨­å®š
BATCH_SIZE = 20
MAX_RETRIES = 2

# --- 2. è¼”åŠ©å·¥å…· (Helpers) ---

def load_tickers(key):
    """å¾ resource è®€å–è‚¡ç¥¨æ¸…å–®"""
    filename = FILES.get(key)
    if not filename: return []
    path = os.path.join(RESOURCE_DIR, filename)
    if not os.path.exists(path):
        # å˜—è©¦å›é€€åˆ° V6.0 ç›®éŒ„æŸ¥æ‰¾ (ç›¸å®¹æ€§)
        alt_path = path.replace('V6.1', 'V6.0')
        if os.path.exists(alt_path):
            path = alt_path
        else:
            return []
            
    try:
        with open(path, 'r', encoding='utf-8') as f:
            raw_list = json.load(f)
        # æ¸…æ´— Ticker æ ¼å¼ (å»é™¤ 'NYSE:', '.' è½‰ '-')
        return list(set([t.split(':')[-1].strip().replace('.', '-') for t in raw_list]))
    except Exception as e:
        print(f"[Error] Load {filename} failed: {e}")
        return []

def get_calendar_status(target_date=None):
    """åˆ¤æ–·æ—¥æ›†æ•ˆæ‡‰ (TOTM, Pre-Holiday)"""
    if target_date is None:
        target_date = datetime.now().date()
    
    start_date = target_date - timedelta(days=40)
    end_date = target_date + timedelta(days=40)
    us_bd = CustomBusinessDay(calendar=USFederalHolidayCalendar())
    dates = pd.date_range(start=start_date, end=end_date, freq=us_bd)
    
    # TOTM: æœˆæœ« 1 å¤© + æœˆåˆ 3 å¤©
    df = pd.DataFrame(index=dates)
    date_series = df.index.to_series()
    groups = date_series.groupby(date_series.dt.to_period('M'))
    totm_dates = []
    for _, days in groups:
        if len(days) < 4: continue
        totm_dates.append(days[-1].date())
        totm_dates.extend([d.date() for d in days[:3]])
        
    is_totm = target_date in totm_dates

    # Pre-Holiday
    cal = USFederalHolidayCalendar()
    holidays = cal.holidays(start=start_date, end=end_date)
    is_pre_holiday = (target_date + timedelta(days=1)) in holidays
    
    # ç‹€æ…‹å­—ä¸²
    status = []
    if is_totm: status.append("TOTM(æœˆåˆ)")
    if is_pre_holiday: status.append("Holiday(ç¯€å‰)")
    
    return is_totm, is_pre_holiday, " + ".join(status) if status else "Normal"

def get_crypto_sentiment():
    """åˆ¤æ–· ETH é€±æœ«æƒ…ç·’ (åƒ…é€±ä¸€æœ‰æ•ˆ)"""
    if datetime.now().weekday() != 0:
        return 0.0, "Weekday"

    try:
        df = yf.download("ETH-USD", period="5d", interval="1h", progress=False, auto_adjust=False)
        if df.empty: return 0.0, "NoData"
        
        # è™•ç†æ™‚å€
        if df.index.tz is None:
            df.index = df.index.tz_localize('UTC').tz_convert('America/New_York')
        else:
            df.index = df.index.tz_convert('America/New_York')
            
        now_price = float(df['Close'].iloc[-1])
        
        # æ‰¾ä¸Šé€±äº” 16:00
        today = datetime.now().date()
        last_friday = today - timedelta(days=3)
        target_ts = pd.Timestamp(f"{last_friday} 16:00").tz_localize('America/New_York')
        
        # æ‰¾æœ€è¿‘çš„æ™‚é–“é»
        idx = df.index.get_indexer([target_ts], method='nearest')[0]
        fri_price = float(df['Close'].iloc[idx])
        
        ret = (now_price - fri_price) / fri_price
        return ret, "Weekend_Move"
    except:
        return 0.0, "Error"

def get_current_vix():
    """ç²å–å³æ™‚ VIX"""
    try:
        df = yf.download("^VIX", period="5d", interval="1d", progress=False, auto_adjust=True)
        return float(df['Close'].iloc[-1])
    except:
        return 20.0 # Fallback

# --- 3. æ ¸å¿ƒæ•¸æ“šè™•ç† (Data Processing) ---

def download_data_batch(tickers):
    """åˆ†æ‰¹ä¸‹è¼‰æ—¥ç·šèˆ‡åˆ†æ™‚ç·š"""
    daily_data = {}
    intra_data = {}
    
    total = len(tickers)
    for i in range(0, total, BATCH_SIZE):
        batch = tickers[i:i+BATCH_SIZE]
        print(f"  Fetching batch {i+1}-{min(i+BATCH_SIZE, total)}...", end='\r')
        
        try:
            # æ—¥ç·š (ç”¨æ–¼è¨ˆç®— RSI, ATR, Vol MA)
            d = yf.download(batch, period="2mo", interval="1d", progress=False, auto_adjust=True, threads=True)
            # åˆ†æ™‚ (ç”¨æ–¼æŠ“æœ€æ–°ç›¤å‰åƒ¹/é–‹ç›¤åƒ¹)
            m = yf.download(batch, period="5d", interval="1m", prepost=True, progress=False, auto_adjust=True, threads=True)
            
            # æ•´ç†æ•¸æ“šçµæ§‹
            if not d.empty:
                # è™•ç† Single/Multi Index
                if isinstance(d.columns, pd.MultiIndex):
                    d = d.stack(level=1, future_stack=True).rename_axis(['Date', 'Ticker']).reset_index()
                else:
                    d['Ticker'] = batch[0]
                    d = d.reset_index()
                
                # å­˜å…¥ Dict
                for t, group in d.groupby('Ticker'):
                    daily_data[t] = group.set_index('Date').sort_index()

            if not m.empty:
                if isinstance(m.columns, pd.MultiIndex):
                    m = m.stack(level=1, future_stack=True).rename_axis(['Datetime', 'Ticker']).reset_index()
                else:
                    m['Ticker'] = batch[0]
                    m = m.reset_index()
                
                for t, group in m.groupby('Ticker'):
                    # è½‰æ›æ™‚å€çµ±ä¸€ç‚º NY
                    df_m = group.set_index('Datetime')
                    if df_m.index.tz is None:
                        df_m.index = df_m.index.tz_localize('UTC').tz_convert('America/New_York')
                    else:
                        df_m.index = df_m.index.tz_convert('America/New_York')
                    intra_data[t] = df_m.sort_index()
                    
        except Exception as e:
            print(f"Batch failed: {e}")
            continue
            
    print(f"\n  Data fetch complete. Daily: {len(daily_data)}, Intraday: {len(intra_data)}")
    return daily_data, intra_data

def prepare_ai_features(ticker, df_daily, df_intra, vix_val):
    """
    ç‚º EXP-07 æ¨¡å‹æº–å‚™ç‰¹å¾µ
    Features: ['RSI_14', 'ATR_Pct', 'Vol_Ratio', 'Gap_Pct', 'VIX']
    """
    try:
        # å¼·åˆ¶è½‰æ•¸å€¼
        for c in ['Open', 'High', 'Low', 'Close', 'Volume']:
            df_daily[c] = pd.to_numeric(df_daily[c], errors='coerce')
        
        df_daily = df_daily.dropna()
        if len(df_daily) < 25: return None, 0, 0 # è³‡æ–™ä¸è¶³

        # 1. å–å¾—æœ€æ–°åƒ¹æ ¼ (Real-time Gap)
        # è‹¥æœ‰åˆ†æ™‚æ•¸æ“šï¼Œå–æœ€å¾Œä¸€ç­† (å¯èƒ½æ˜¯ç›¤å‰æˆ–é–‹ç›¤)
        if ticker in df_intra and not df_intra[ticker].empty:
            curr_price = float(df_intra[ticker]['Close'].iloc[-1])
        else:
            # è‹¥ç„¡åˆ†æ™‚ï¼Œæš«æ™‚ç”¨æ—¥ç·šæ”¶ç›¤ (é€™åœ¨ç›¤å¾Œè·‘æ²’å•é¡Œï¼Œç›¤å‰è·‘æœƒå¤±çœŸ)
            curr_price = float(df_daily['Close'].iloc[-1])
            
        prev_close = float(df_daily['Close'].iloc[-1])
        # è‹¥ curr_price == prev_close (å°šæœªé–‹ç›¤)ï¼Œå‰‡ Gap ç‚º 0
        
        gap_pct = (curr_price - prev_close) / prev_close

        # 2. è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ (åŸºæ–¼ T-1 æ­·å²æ•¸æ“š)
        # EXP-07 è¨“ç·´æ™‚æ˜¯ç”¨ "T-1 çš„æŒ‡æ¨™" ä¾†é æ¸¬ "T çš„ç²åˆ©"
        # å› æ­¤æˆ‘å€‘ç›´æ¥åœ¨æ—¥ç·šä¸Šç®—ï¼Œå–æœ€å¾Œä¸€ç­†å³å¯
        
        # RSI 14
        rsi_series = ta.rsi(df_daily['Close'], length=14)
        rsi_val = rsi_series.iloc[-1]
        
        # ATR 14
        atr_series = ta.atr(df_daily['High'], df_daily['Low'], df_daily['Close'], length=14)
        atr_val = atr_series.iloc[-1]
        atr_pct = atr_val / prev_close
        
        # Vol Ratio (æ˜¨æ—¥é‡ / å‰20æ—¥å‡é‡)
        # æ³¨æ„: è¨“ç·´æ™‚é‚è¼¯æ˜¯ df['Prev_Vol'] / df['Vol_MA20'].shift(1)
        # æ­¤è™• iloc[-1] æ˜¯ Prev_Vol (T-1)
        vol = df_daily['Volume']
        vol_last = vol.iloc[-1]
        
        # MA20 (ä¸åŒ…å« T-1 çš„ rolling mean? éœ€å°å¿ƒ)
        # rolling(20).mean() åœ¨ T-1 æ™‚åŒ…å«äº† T-1ã€‚
        # shift(1) ä»£è¡¨ T-2 çš„ rolling meanã€‚
        vol_ma = vol.rolling(20).mean()
        vol_ma_ref = vol_ma.iloc[-2] # T-2 çš„ MA20
        
        vol_ratio = vol_last / vol_ma_ref if vol_ma_ref > 0 else 1.0
        
        # 3. çµ„åˆç‰¹å¾µ DataFrame
        features = pd.DataFrame([[rsi_val, atr_pct, vol_ratio, gap_pct, vix_val]], 
                                columns=['RSI_14', 'ATR_Pct', 'Vol_Ratio', 'Gap_Pct', 'VIX'])
        
        return features, gap_pct, curr_price
        
    except Exception as e:
        # print(f"Feature calc error for {ticker}: {e}")
        return None, 0, 0

# --- 4. ä¸»ç¨‹å¼ (Dashboard Generator) ---

def generate_live_dashboard():
    print("="*60)
    print(f"ğŸš€ V6.1 Gap Signal Generator (AI Enhanced)")
    print(f"â° Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60)

    # 1. è¼‰å…¥æ¨¡å‹
    ai_model = None
    if os.path.exists(MODEL_PATH):
        try:
            ai_model = joblib.load(MODEL_PATH)
            print(f"[System] AI Model loaded: EXP-07 XGBoost")
        except Exception as e:
            print(f"[Warning] Failed to load model: {e}")
    else:
        print(f"[Warning] Model not found at {MODEL_PATH}. Running in Classic Mode.")

    # 2. è¼‰å…¥æ¸…å–®
    # åˆä½µ Asset Pool èˆ‡ Toxic Poolï¼Œä¸¦ç§»é™¤é‡è¤‡
    pool_asset = load_tickers('ASSET')
    pool_toxic = load_tickers('TOXIC')
    pool_holding = load_tickers('HOLDING') # é¸é …: åŠ å…¥æŒå€‰ç›£æ§
    
    all_tickers = list(set(pool_asset + pool_toxic + pool_holding))
    print(f"[System] Monitoring {len(all_tickers)} tickers.")
    
    # 3. ç²å–ç’°å¢ƒæ•¸æ“š
    is_totm, is_holiday, cal_status = get_calendar_status()
    crypto_ret, crypto_status = get_crypto_sentiment()
    curr_vix = get_current_vix()
    
    print(f"\n[Market Context]")
    print(f"  ğŸ“… Calendar: {cal_status}")
    print(f"  ğŸŒŠ VIX     : {curr_vix:.2f}")
    if crypto_status == "Weekend_Move":
        print(f"  ğŸª™ Crypto  : ETH Weekend {crypto_ret*100:+.2f}%")
        
    # 4. ä¸‹è¼‰è‚¡ç¥¨æ•¸æ“š
    print("\n[Data Fetching]")
    daily_map, intra_map = download_data_batch(all_tickers)
    
    # 5. åˆ†æè¨Šè™Ÿ
    signals = []
    
    print("\n[Analysis]")
    for ticker in all_tickers:
        if ticker not in daily_map: continue
        
        # æº–å‚™ç‰¹å¾µèˆ‡è¨ˆç®— Gap
        features, gap_pct, price = prepare_ai_features(
            ticker, daily_map[ticker], intra_map, curr_vix
        )
        
        if features is None: continue
        
        # åŸºç¤æ¿¾ç¶²: Gap > 0.5%
        if gap_pct <= GAP_THRESHOLD: continue
        
        # å–å¾— Pool å±¬æ€§
        is_toxic = ticker in pool_toxic
        pool_tag = "Toxic" if is_toxic else "Asset"
        
        # --- AI é æ¸¬ ---
        ai_prob = 0.5
        ai_rec = "N/A"
        
        if ai_model:
            try:
                # XGBoost predict
                ai_prob = ai_model.predict_proba(features)[0][1] # Class 1 Prob
                ai_rec = "âœ… GO" if ai_prob > AI_CONFIDENCE_LV else "âŒ SKIP"
            except:
                ai_rec = "Err"
        
        # --- è¦å‰‡æ¿¾ç¶² (Context Rules) ---
        rule_action = "PASS"
        rule_reason = ""
        
        # Rule 1: Crypto Filter (åƒ…é‡å° Toxic)
        if is_toxic and crypto_status == "Weekend_Move" and crypto_ret > 0.05:
            rule_action = "BLOCK"
            rule_reason = "Crypto Surge"
            
        # Rule 2: Calendar Filter (é‡å° Asset)
        if not is_toxic:
            if is_holiday:
                rule_action = "BLOCK"
                rule_reason = "Pre-Holiday"
            elif is_totm:
                rule_action = "BLOCK"
                rule_reason = "TOTM Flow"
                
        # --- æ•´åˆæ±ºç­– ---
        final_decision = "WAIT"
        if rule_action == "BLOCK":
            final_decision = f"â›” {rule_reason}"
        elif ai_model and ai_prob < AI_CONFIDENCE_LV:
            final_decision = "ğŸ“‰ AI Low Conf"
        else:
            final_decision = "ğŸš€ ACTION"
            
        # æ”¶é›†çµæœ
        signals.append({
            'Ticker': ticker,
            'Pool': pool_tag,
            'Price': price,
            'Gap%': gap_pct,
            'RSI': features['RSI_14'].iloc[0],
            'ATR%': features['ATR_Pct'].iloc[0],
            'VolRatio': features['Vol_Ratio'].iloc[0],
            'AI_Prob': ai_prob,
            'Decision': final_decision
        })
        
    # 6. è¼¸å‡ºå ±è¡¨
    if not signals:
        print("\nNo Gap signals detected (> 0.5%).")
        return

    df_res = pd.DataFrame(signals)
    df_res.sort_values('AI_Prob', ascending=False, inplace=True)
    
    # é¡¯ç¤º
    print("\n" + "="*95)
    print(f"{'Ticker':<6} {'Pool':<6} {'Price':>8} {'Gap%':>7} {'RSI':>4} {'ATR%':>5} {'VolR':>5} {'AI Prob':>8} {'Decision':<15}")
    print("-" * 95)
    
    for _, r in df_res.iterrows():
        # é¡è‰²æ¨™è¨˜ (å¦‚æœç’°å¢ƒæ”¯æ´ ANSI)
        dec = r['Decision']
        prob_str = f"{r['AI_Prob']:.0%}"
        
        # ç°¡å–®æ‰“å°
        print(f"{r['Ticker']:<6} {r['Pool']:<6} {r['Price']:>8.2f} {r['Gap%']*100:>6.2f}% "
              f"{r['RSI']:>4.0f} {r['ATR%']*100:>4.1f}% {r['VolRatio']:>5.1f} {prob_str:>8} {dec:<15}")
              
    print("="*95)
    
    # å­˜æª”
    csv_path = os.path.join(OUTPUT_DIR, f'daily_signals_{datetime.now().strftime("%Y%m%d")}.csv')
    df_res.to_csv(csv_path, index=False)
    print(f"\nReport saved to: {csv_path}")

if __name__ == '__main__':
    try:
        generate_live_dashboard()
    except KeyboardInterrupt:
        print("\nStopped by user.")