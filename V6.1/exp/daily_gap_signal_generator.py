import os
import sys
import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime, timedelta, date
import json
import time
import logging
from pandas.tseries.holiday import USFederalHolidayCalendar
from pandas.tseries.offsets import CustomBusinessDay

# --- 0. æŠ‘åˆ¶ yfinance çš„é›œè¨Š ---
# yfinance çš„éŒ¯èª¤è¨Šæ¯æœ‰æ™‚æœƒç›´æ¥ print åˆ° stderrï¼Œé€™è£¡å°‡å…¶ logger ç´šåˆ¥èª¿é«˜ï¼Œåªé¡¯ç¤º Critical
logger = logging.getLogger('yfinance')
logger.setLevel(logging.CRITICAL)

# --- 1. è¨­å®šèˆ‡åƒæ•¸ ---

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
RESOURCE_DIR = os.path.join(BASE_DIR, '..', 'resource')
OUTPUT_DIR = os.path.join(BASE_DIR, 'output')
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ä¾†æºæª”æ¡ˆ
ASSET_POOL_FILE = '2025_final_asset_pool.json'
TOXIC_POOL_FILE = '2025_final_toxic_asset_pool.json'
SENSITIVE_POOL_FILE = '2025_final_crypto_sensitive_pool.json'

# å‹•èƒ½è‚¡é»‘åå–® (Momentum Blacklist)
MOMENTUM_BLACKLIST = [
    'NVDA', 'APP', 'NET', 'ANET', 'AMD', 'MSFT', 'GOOG', 'AMZN', 
    'LLY', 'NVO', 'V', 'MCD', 'IBM', 'QCOM', 'SMCI', 'PLTR', 'COIN', 'MSTR'
]

# ç­–ç•¥åƒæ•¸
DEFAULT_GAP_THRESHOLD = 0.005  # 0.5%
FADE_THRESHOLD_PCT = 0.010     # 1.0%
CRYPTO_YELLOW_THRESHOLD = 0.01 # 1%
CRYPTO_RED_THRESHOLD = 0.05    # 5%

# ä¸‹è¼‰è¨­å®š
BATCH_SIZE = 20  # æ¯æ¬¡ä¸‹è¼‰ 20 æª”ï¼Œé¿å… Timeout
MAX_RETRIES = 2  # å¤±æ•—é‡è©¦æ¬¡æ•¸

# --- 2. å·¥å…·å‡½æ•¸ ---

def load_tickers_from_json(filename):
    path = os.path.join(RESOURCE_DIR, filename)
    if not os.path.exists(path):
        return []
    try:
        with open(path, 'r', encoding='utf-8') as f:
            raw_list = json.load(f)
        cleaned_list = [t.split(':')[-1].strip().replace('.', '-') for t in raw_list]
        return list(set(cleaned_list))
    except Exception as e:
        print(f"[Error] ç„¡æ³•è®€å–æ¸…å–® {filename}: {e}")
        return []

def get_calendar_status(target_date=None):
    """åˆ¤æ–·æŒ‡å®šæ—¥æœŸ (é è¨­ä»Šæ—¥) æ˜¯å¦ç‚º TOTM æˆ– Pre-Holiday"""
    if target_date is None:
        target_date = datetime.now().date()
    
    start_date = target_date - timedelta(days=35)
    end_date = target_date + timedelta(days=35)
    us_bd = CustomBusinessDay(calendar=USFederalHolidayCalendar())
    dates = pd.date_range(start=start_date, end=end_date, freq=us_bd)
    
    df = pd.DataFrame(index=dates)
    
    # è¨ˆç®— TOTM
    date_series = df.index.to_series()
    groups = date_series.groupby(date_series.dt.to_period('M'))
    totm_dates = []
    for period, dates_in_month in groups:
        days = dates_in_month.index
        if len(days) < 4: continue
        totm_dates.append(days[-1])
        totm_dates.extend(days[:3])
        
    is_totm = target_date in [d.date() for d in totm_dates]

    # è¨ˆç®— Pre-Holiday
    cal = USFederalHolidayCalendar()
    holidays = cal.holidays(start=start_date, end=end_date)
    is_pre_holiday = False
    
    # æ‰¾ target_date åœ¨äº¤æ˜“æ—¥æ›†çš„ index
    try:
        loc = dates.get_loc(pd.Timestamp(target_date))
        if loc < len(dates) - 1:
            next_trade_day = dates[loc + 1].date()
            # æª¢æŸ¥ä¸‹ä¸€å€‹äº¤æ˜“æ—¥ä¹‹å‰æ˜¯å¦æœ‰å‡æœŸ
            # ç°¡å–®é‚è¼¯ï¼šè‹¥ä¸‹ä¸€å€‹äº¤æ˜“æ—¥ > target_date + 1 (ä¸”éé€±æœ«)ï¼Œé€šå¸¸æ„å‘³è‘—ä¸­é–“æœ‰å‡æœŸ
            # ä½†æ›´æº–ç¢ºçš„æ˜¯ç›´æ¥æ¯”å° holidays
            # é€™è£¡æ¡ç”¨ï¼šå¦‚æœæ˜å¤©ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œä¸”æ˜å¤©æ˜¯ Holiday (æˆ–æ˜å¤©é€±å…­ä½†é€±äº”æ˜¯ Holiday)
            # ç‚ºäº†ç°¡åŒ–ä¸”æº–ç¢ºï¼šæª¢æŸ¥ target_date + 1 æ˜¯å¦ç‚º holiday
            tomorrow = target_date + timedelta(days=1)
            if tomorrow in holidays:
                is_pre_holiday = True
            # æˆ–è€…ï¼šå¦‚æœä¸‹ä¸€å€‹äº¤æ˜“æ—¥è·Ÿä»Šå¤©å·®è¶…é 3 å¤© (é€±æœ«æ˜¯ 3 å¤©ï¼Œé•·é€±æœ«æ˜¯ 4 å¤©)
            elif (next_trade_day - target_date).days > 3:
                is_pre_holiday = True
    except KeyError:
        pass 

    status_parts = []
    if is_totm: status_parts.append("TOTM(æœˆåˆ)")
    if is_pre_holiday: status_parts.append("Pre-Holiday(ç¯€å‰)")
    
    status_str = " + ".join(status_parts) if status_parts else "Normal(ä¸€èˆ¬æ—¥)"
    
    return is_totm, is_pre_holiday, status_str

def get_crypto_sentiment():
    """å›å‚³: (æ¼²è·Œå¹…, ç‹€æ…‹, Emoji)"""
    if datetime.now().weekday() != 0: 
        return 0.0, "Weekday", "âšª"

    try:
        # æ¶ˆé™¤ FutureWarning: auto_adjust=False
        df = yf.download("ETH-USD", period="5d", interval="1h", progress=False, auto_adjust=False)
        
        if df.empty: return 0.0, "NoData", "âšª"
        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
        
        if df.index.tz is None:
            df.index = df.index.tz_localize('UTC').tz_convert('America/New_York')
        else:
            df.index = df.index.tz_convert('America/New_York')

        now_price = float(df['Close'].iloc[-1])
        
        today = datetime.now().date()
        last_friday = today - timedelta(days=3)
        target_time = pd.Timestamp(f"{last_friday} 16:00").tz_localize('America/New_York')
        
        try:
            idx = df.index.get_indexer([target_time], method='nearest')[0]
            fri_price = float(df['Close'].iloc[idx])
        except:
            fri_price = float(df['Close'].iloc[0])
        
        if fri_price == 0: return 0.0, "Error", "âšª"

        ret = (now_price - fri_price) / fri_price
        
        if ret > CRYPTO_RED_THRESHOLD:
            return ret, "RED", "ğŸ”´"
        elif ret > CRYPTO_YELLOW_THRESHOLD:
            return ret, "YELLOW", "ğŸŸ¡"
        else:
            return ret, "GREEN", "ğŸŸ¢"

    except Exception:
        return 0.0, "Error", "âšª"

def download_data_in_batches(tickers, period, interval, prepost=False):
    """
    åˆ†æ‰¹ä¸‹è¼‰æ•¸æ“šä»¥é¿å… Timeout
    """
    all_data = []
    total = len(tickers)
    
    for i in range(0, total, BATCH_SIZE):
        batch = tickers[i:i + BATCH_SIZE]
        # ç°¡å–®é€²åº¦é¡¯ç¤º
        # print(f"  Downloading batch {i//BATCH_SIZE + 1}/{(total-1)//BATCH_SIZE + 1} ({len(batch)} tickers)...")
        
        for attempt in range(MAX_RETRIES):
            try:
                # é—œéµä¿®æ­£ï¼šåŠ å…¥ auto_adjust=False, threads=True (åŠ é€Ÿ)
                df = yf.download(
                    batch, 
                    period=period, 
                    interval=interval, 
                    prepost=prepost, 
                    progress=False, 
                    auto_adjust=False,
                    threads=True
                )
                
                # yfinance æœ‰æ™‚å›å‚³ç©º DataFrame
                if not df.empty:
                    all_data.append(df)
                break # æˆåŠŸå‰‡è·³å‡ºé‡è©¦
            except Exception as e:
                if attempt < MAX_RETRIES - 1:
                    time.sleep(1) # ç¨ä½œä¼‘æ¯å¾Œé‡è©¦
                else:
                    print(f"  [Warning] Batch failed: {batch[0]}... {e}")

    if not all_data:
        return pd.DataFrame()
        
    # åˆä½µæ•¸æ“š
    # æ³¨æ„ï¼šyfinance çš„ MultiIndex è¡Œç‚º
    # å¦‚æœåªæœ‰ä¸€å€‹ batch ä¸”åªæœ‰ä¸€æª”è‚¡ç¥¨ï¼Œçµæ§‹å¯èƒ½ä¸åŒï¼Œé€™è£¡å˜—è©¦é€šç”¨çš„ concat
    try:
        # å¦‚æœæ˜¯å¤šå€‹ batchï¼Œéœ€è¦åˆä½µ
        if len(all_data) == 1:
            return all_data[0]
        
        # é‡å° Column é€²è¡Œåˆä½µ (Date index æ˜¯ç›¸åŒçš„)
        # yfinance download å¤šæª”è‚¡ç¥¨æ™‚ï¼ŒColumns æ˜¯ (Price Type, Ticker)
        # æˆ‘å€‘éœ€è¦æ°´å¹³åˆä½µ (axis=1)
        full_df = pd.concat(all_data, axis=1)
        return full_df
    except Exception as e:
        print(f"  [Error] Data merge failed: {e}")
        return pd.DataFrame()

def get_market_data(tickers):
    print(f"[{datetime.now().strftime('%H:%M:%S')}] æ­£åœ¨ä¸‹è¼‰ {len(tickers)} æª”è‚¡ç¥¨æ•¸æ“š (åˆ†æ‰¹è™•ç†)...")
    data_map = {}
    
    # 1. ä¸‹è¼‰æ—¥ç·š (Batch)
    try:
        df_daily = download_data_in_batches(tickers, period="1mo", interval="1d")
        
        if df_daily.empty: return {}
        
        # è™•ç† MultiIndex
        if isinstance(df_daily.columns, pd.MultiIndex): 
            # é€™æ˜¯æ¨™æº–æƒ…æ³
            closes = df_daily['Close']
            highs = df_daily['High']
            lows = df_daily['Low']
        else:
            # å–®ä¸€è‚¡ç¥¨æƒ…æ³ (yfinance æœ‰æ™‚æœƒé™ç¶­)
            # ç‚ºäº†é€šç”¨æ€§ï¼Œæ‰‹å‹•è½‰å› DataFrame
            closes = pd.DataFrame({tickers[0]: df_daily['Close']})
            highs = pd.DataFrame({tickers[0]: df_daily['High']})
            lows = pd.DataFrame({tickers[0]: df_daily['Low']})
            
    except Exception as e:
        print(f"[Error] æ—¥ç·šä¸‹è¼‰å¤±æ•—: {e}")
        return {}

    # 2. ä¸‹è¼‰ç›¤å‰ (Batch)
    try:
        df_intraday = download_data_in_batches(tickers, period="5d", interval="1m", prepost=True)
        
        if df_intraday.empty: 
            # ç›¤å‰æ•¸æ“šå¤±æ•—ä¸æ‡‰é˜»æ“‹ä¸»æµç¨‹ï¼Œå›å‚³å·²æœ‰çš„æ—¥ç·šæ•¸æ“šå³å¯
            # ä½†éœ€æ¨™è¨˜ç„¡ç›¤å‰
            pass
        else:
            if df_intraday.index.tz is None:
                df_intraday.index = df_intraday.index.tz_localize('UTC').tz_convert('America/New_York')
            else:
                df_intraday.index = df_intraday.index.tz_convert('America/New_York')
            
        current_date = df_intraday.index[-1].date() if not df_intraday.empty else date.today()
        
    except Exception as e:
        print(f"[Error] åˆ†æ™‚æ•¸æ“šä¸‹è¼‰å¤±æ•—: {e}")
        return {}

    # 3. æ•´åˆæ•¸æ“š
    for ticker in tickers:
        try:
            # --- æ—¥ç·šè™•ç† ---
            if ticker not in closes.columns: 
                # å¯èƒ½ä¸‹è¼‰å¤±æ•—æˆ– Delisted
                continue
            
            c = closes[ticker].dropna()
            h = highs[ticker].dropna()
            l = lows[ticker].dropna()
            
            if len(c) < 15: continue
            prev_close = float(c.iloc[-1])
            
            # ATR è¨ˆç®—
            tr = h - l 
            atr = tr.rolling(14).mean().iloc[-1]
            atr_pct = atr / prev_close if prev_close > 0 else 0

            # --- ç›¤å‰è™•ç† ---
            curr_price = np.nan
            pre_high = np.nan
            
            if not df_intraday.empty and ticker in df_intraday['Close'].columns:
                series_c = df_intraday['Close'][ticker]
                # å˜—è©¦ç²å– Highï¼Œè‹¥ç„¡å‰‡ç”¨ Close
                if 'High' in df_intraday.columns and ticker in df_intraday['High'].columns:
                    series_h = df_intraday['High'][ticker]
                else:
                    series_h = series_c
                
                # ç¯©é¸ä»Šæ—¥
                today_mask = series_c.index.date == current_date
                today_close = series_c[today_mask]
                today_high = series_h[today_mask]
                
                if not today_close.empty:
                    curr_price = float(today_close.iloc[-1])
                    pre_high = float(today_high.max())

            # --- Pre-Fade è¨ˆç®— ---
            pre_fade = 0.0
            if pd.notna(pre_high) and pre_high > 0 and pd.notna(curr_price):
                pre_fade = (pre_high - curr_price) / pre_high

            data_map[ticker] = {
                'prev_close': prev_close, 
                'curr_price': curr_price, 
                'pre_high': pre_high, 
                'pre_fade': pre_fade, 
                'atr_pct': atr_pct
            }
        except Exception:
            continue
            
    return data_map

def generate_live_dashboard():
    print(f"\n>>> V6.1 Gap Strategy Dashboard (Optimized)")
    print(f">>> Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("-" * 60)
    
    # 1. è¼‰å…¥æ¸…å–®
    pool_toxic = load_tickers_from_json(TOXIC_POOL_FILE)
    pool_asset = load_tickers_from_json(ASSET_POOL_FILE)
    pool_sensitive = load_tickers_from_json(SENSITIVE_POOL_FILE)
    
    all_tickers = list(set(pool_toxic + pool_asset + pool_sensitive))
    # æ’é™¤é»‘åå–®
    valid_tickers = [t for t in all_tickers if t not in MOMENTUM_BLACKLIST]
    
    print(f"æ¸…å–®æ¦‚æ³:")
    print(f"  - Asset Pool (A): {len(pool_asset)} æª”")
    print(f"  - Toxic Pool (T): {len(pool_toxic)} æª”")
    print(f"  - Sensitive Pool (S): {len(pool_sensitive)} æª”")
    print(f"  - ç›£æ§ç¸½æ•¸: {len(valid_tickers)} æª”")

    # 2. å–å¾—ç’°å¢ƒç‹€æ…‹
    is_totm, is_pre_holiday, cal_status_str = get_calendar_status()
    eth_ret, eth_status, eth_light = get_crypto_sentiment()
    
    print(f"\n[Market Context]")
    print(f"  ğŸ“… Calendar: {cal_status_str}")
    
    if is_totm:
        print(f"     ğŸ‘‰ Asset Pool: âš ï¸ æš«åœäº¤æ˜“ (æœˆåˆæ³•äººè²·ç›¤)")
        print(f"     ğŸ‘‰ Toxic Pool: ğŸ”¥ ç©æ¥µäº¤æ˜“ (è³‡é‡‘å†å¹³è¡¡æ•ˆæ‡‰)")
    if is_pre_holiday:
        print(f"     ğŸ‘‰ All Pools : âš ï¸ ç¯€å‰é‡ç¸® (å°å¿ƒå‡è¨Šè™Ÿ)")

    if eth_status != "Weekday":
        print(f"  ğŸª™ Crypto: ETH {eth_ret*100:+.2f}% {eth_light}")
        if eth_status == "RED":
            print(f"     ğŸ‘‰ Toxic/Sensitive: â›” æš«åœäº¤æ˜“ (ETH > 5% æš´æ¼²)")
    else:
        print(f"  ğŸª™ Crypto: å¹³æ—¥æ¨¡å¼ (ç„¡é€±æœ«æ¿¾ç¶²)")

    # 3. å–å¾—æ•¸æ“š (å·²å„ªåŒ–)
    market_data = get_market_data(valid_tickers)
    
    # æª¢æŸ¥æ˜¯å¦æœ‰æ•¸æ“šå›å‚³
    if not market_data:
        print("\n[Error] ç„¡æ³•ç²å–ä»»ä½•å¸‚å ´æ•¸æ“šï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£ç·šæˆ–ä»£ç¢¼æ¸…å–®ã€‚")
        return

    report_data = []
    
    for ticker in valid_tickers:
        if ticker not in market_data: continue
        data = market_data[ticker]
        
        curr_price = data['curr_price']
        prev_close = data['prev_close']
        
        # éæ¿¾æ‰ç„¡æ•ˆæ•¸æ“š
        if pd.isna(curr_price) or prev_close <= 0: continue
        
        gap_pct = (curr_price - prev_close) / prev_close
        
        # åªçœ‹ Gap Up
        if gap_pct <= 0: continue
            
        # åˆ†é¡èˆ‡é‚è¼¯
        if ticker in pool_toxic:
            category = "Toxic"; cat_code = "T"
        elif ticker in pool_sensitive:
            category = "Sensitive"; cat_code = "S"
        else:
            category = "Asset"; cat_code = "A"
            
        atr_pct = data['atr_pct']
        pre_fade = data['pre_fade']
        
        # å‹•æ…‹é–€æª»
        if category in ["Toxic", "Sensitive"]:
            dynamic_threshold = max(DEFAULT_GAP_THRESHOLD, 0.3 * atr_pct)
        else:
            dynamic_threshold = DEFAULT_GAP_THRESHOLD
            
        # è¨Šè™Ÿåˆ¤æ–·
        status = "WAIT"
        score = 0
        
        if gap_pct > dynamic_threshold:
            if category in ["Toxic", "Sensitive"] and eth_status == "RED":
                status = "âœ‹ HOLD (ETH)"; score = -2
            elif category == "Asset" and (is_totm or is_pre_holiday):
                status = "âœ‹ SKIP (Calendar)"; score = -1
            elif category in ["Toxic", "Sensitive"] and is_totm:
                if pre_fade > FADE_THRESHOLD_PCT:
                    status = "ğŸ”¥ğŸ”¥ TOTM SELL"; score = 4
                else:
                    status = "ğŸ”¥ TOTM (Fade?)"; score = 2
            else:
                if category in ["Toxic", "Sensitive"] and eth_status == "YELLOW":
                    if pre_fade > FADE_THRESHOLD_PCT:
                        status = "âš ï¸ RISKY SELL"; score = 1
                    else:
                        status = "WAIT (Yellow)"; score = 0
                elif category in ["Toxic", "Sensitive"] and is_pre_holiday:
                     if pre_fade > FADE_THRESHOLD_PCT:
                        status = "âš ï¸ Holiday SELL"; score = 1
                     else:
                        status = "WAIT (Holiday)"; score = 0
                else:
                    if pre_fade > FADE_THRESHOLD_PCT:
                        status = "ğŸ”´ STRONG SELL"; score = 3
                    else:
                        status = "ğŸ”´ SELL"; score = 2
        
        report_data.append({
            'Ticker': ticker, 'Cat': cat_code,
            'Gap%': gap_pct, 'Thres%': dynamic_threshold,
            'Fade%': pre_fade, 'ATR%': atr_pct,
            'Price': curr_price, 'Status': status, 'Score': score
        })
            
    # 4. è¼¸å‡ºå ±è¡¨
    if not report_data:
        print("\nç„¡ Gap > 0 æ¨™çš„ã€‚")
        return

    df = pd.DataFrame(report_data)
    df.sort_values(by=['Score', 'Gap%'], ascending=[False, False], inplace=True)
    
    print("\n" + "="*95)
    print(f"{'Ticker':<6} {'Cat':<3} {'Gap%':>7} {'Thres%':>7} {'Fade%':>7} {'ATR%':>6} {'Price':>8} {'Status':<20}")
    print("-" * 95)
    
    for _, row in df.iterrows():
        mark = ">>" if row['Score'] >= 2 else "  "
        if row['Score'] < 0: mark = "XX"
        
        print(f"{mark} {row['Ticker']:<6} {row['Cat']:<3} "
              f"{row['Gap%']*100:>6.2f}% {row['Thres%']*100:>6.2f}% "
              f"{row['Fade%']*100:>6.2f}% {row['ATR%']*100:>5.1f}% "
              f"{row['Price']:>8.2f} {row['Status']:<20}")
    print("="*95)

    outfile = os.path.join(OUTPUT_DIR, f'gap_signals_{datetime.now().strftime("%Y%m%d")}.csv')
    df.to_csv(outfile, index=False)
    print(f"\n[Saved] {outfile}")

if __name__ == '__main__':
    try:
        generate_live_dashboard()
    except KeyboardInterrupt:
        print("\nStopped.")