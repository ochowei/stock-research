import os
import sys
import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime, timedelta, date
import json
import time
import logging
from pandas.tseries.holiday import USFederalHolidayCalendar
from pandas.tseries.offsets import CustomBusinessDay

# --- 0. æŠ‘åˆ¶ yfinance çš„é›œè¨Š ---
# yfinance çš„éŒ¯èª¤è¨Šæ¯æœ‰æ™‚æœƒç›´æ¥ print åˆ° stderrï¼Œé€™è£¡å°‡å…¶ logger ç´šåˆ¥èª¿é«˜ï¼Œåªé¡¯ç¤º Critical
logger = logging.getLogger('yfinance')
logger.setLevel(logging.CRITICAL)

# --- 1. è¨­å®šèˆ‡åƒæ•¸ ---

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
RESOURCE_DIR = os.path.join(BASE_DIR, '..', 'resource')
OUTPUT_DIR = os.path.join(BASE_DIR, 'output')
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ä¾†æºæª”æ¡ˆ
ASSET_POOL_FILE = '2025_final_asset_pool.json'
TOXIC_POOL_FILE = '2025_final_toxic_asset_pool.json'
SENSITIVE_POOL_FILE = '2025_final_crypto_sensitive_pool.json'

# å‹•èƒ½è‚¡é»‘åå–® (Momentum Blacklist)
MOMENTUM_BLACKLIST = [
    'NVDA', 'APP', 'NET', 'ANET', 'AMD', 'MSFT', 'GOOG', 'AMZN', 
    'LLY', 'NVO', 'V', 'MCD', 'IBM', 'QCOM', 'SMCI', 'PLTR', 'COIN', 'MSTR'
]

# ç­–ç•¥åƒæ•¸
DEFAULT_GAP_THRESHOLD = 0.005  # 0.5%
FADE_THRESHOLD_PCT = 0.010     # 1.0%
CRYPTO_YELLOW_THRESHOLD = 0.01 # 1%
CRYPTO_RED_THRESHOLD = 0.05    # 5%

# ä¸‹è¼‰è¨­å®š
BATCH_SIZE = 20  # æ¯æ¬¡ä¸‹è¼‰ 20 æª”ï¼Œé¿å… Timeout
MAX_RETRIES = 2  # å¤±æ•—é‡è©¦æ¬¡æ•¸

# --- 2. å·¥å…·å‡½æ•¸ ---

def load_tickers_from_json(filename):
    path = os.path.join(RESOURCE_DIR, filename)
    if not os.path.exists(path):
        return []
    try:
        with open(path, 'r', encoding='utf-8') as f:
            raw_list = json.load(f)
        cleaned_list = [t.split(':')[-1].strip().replace('.', '-') for t in raw_list]
        return list(set(cleaned_list))
    except Exception as e:
        print(f"[Error] ç„¡æ³•è®€å–æ¸…å–® {filename}: {e}")
        return []

def get_calendar_status(target_date=None):
    """åˆ¤æ–·æŒ‡å®šæ—¥æœŸ (é è¨­ä»Šæ—¥) æ˜¯å¦ç‚º TOTM æˆ– Pre-Holiday"""
    if target_date is None:
        target_date = datetime.now().date()
    
    start_date = target_date - timedelta(days=35)
    end_date = target_date + timedelta(days=35)
    us_bd = CustomBusinessDay(calendar=USFederalHolidayCalendar())
    dates = pd.date_range(start=start_date, end=end_date, freq=us_bd)
    
    df = pd.DataFrame(index=dates)
    
    # è¨ˆç®— TOTM
    date_series = df.index.to_series()
    groups = date_series.groupby(date_series.dt.to_period('M'))
    totm_dates = []
    for period, dates_in_month in groups:
        days = dates_in_month.index
        if len(days) < 4: continue
        totm_dates.append(days[-1])
        totm_dates.extend(days[:3])
        
    is_totm = target_date in [d.date() for d in totm_dates]

    # è¨ˆç®— Pre-Holiday
    cal = USFederalHolidayCalendar()
    holidays = cal.holidays(start=start_date, end=end_date)
    is_pre_holiday = False
    
    # æ‰¾ target_date åœ¨äº¤æ˜“æ—¥æ›†çš„ index
    try:
        loc = dates.get_loc(pd.Timestamp(target_date))
        if loc < len(dates) - 1:
            next_trade_day = dates[loc + 1].date()
            # æª¢æŸ¥ä¸‹ä¸€å€‹äº¤æ˜“æ—¥ä¹‹å‰æ˜¯å¦æœ‰å‡æœŸ
            # ç°¡å–®é‚è¼¯ï¼šè‹¥ä¸‹ä¸€å€‹äº¤æ˜“æ—¥ > target_date + 1 (ä¸”éé€±æœ«)ï¼Œé€šå¸¸æ„å‘³è‘—ä¸­é–“æœ‰å‡æœŸ
            # ä½†æ›´æº–ç¢ºçš„æ˜¯ç›´æ¥æ¯”å° holidays
            # é€™è£¡æ¡ç”¨ï¼šå¦‚æœæ˜å¤©ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œä¸”æ˜å¤©æ˜¯ Holiday (æˆ–æ˜å¤©é€±å…­ä½†é€±äº”æ˜¯ Holiday)
            # ç‚ºäº†ç°¡åŒ–ä¸”æº–ç¢ºï¼šæª¢æŸ¥ target_date + 1 æ˜¯å¦ç‚º holiday
            tomorrow = target_date + timedelta(days=1)
            if tomorrow in holidays:
                is_pre_holiday = True
            # æˆ–è€…ï¼šå¦‚æœä¸‹ä¸€å€‹äº¤æ˜“æ—¥è·Ÿä»Šå¤©å·®è¶…é 3 å¤© (é€±æœ«æ˜¯ 3 å¤©ï¼Œé•·é€±æœ«æ˜¯ 4 å¤©)
            elif (next_trade_day - target_date).days > 3:
                is_pre_holiday = True
    except KeyError:
        pass 

    status_parts = []
    if is_totm: status_parts.append("TOTM(æœˆåˆ)")
    if is_pre_holiday: status_parts.append("Pre-Holiday(ç¯€å‰)")
    
    status_str = " + ".join(status_parts) if status_parts else "Normal(ä¸€èˆ¬æ—¥)"
    
    return is_totm, is_pre_holiday, status_str

def get_crypto_sentiment():
    """å›å‚³: (æ¼²è·Œå¹…, ç‹€æ…‹, Emoji)"""
    if datetime.now().weekday() != 0: 
        return 0.0, "Weekday", "âšª"

    try:
        # æ¶ˆé™¤ FutureWarning: auto_adjust=False
        df = yf.download("ETH-USD", period="5d", interval="1h", progress=False, auto_adjust=False)
        
        if df.empty: return 0.0, "NoData", "âšª"
        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
        
        if df.index.tz is None:
            df.index = df.index.tz_localize('UTC').tz_convert('America/New_York')
        else:
            df.index = df.index.tz_convert('America/New_York')

        now_price = float(df['Close'].iloc[-1])
        
        today = datetime.now().date()
        last_friday = today - timedelta(days=3)
        target_time = pd.Timestamp(f"{last_friday} 16:00").tz_localize('America/New_York')
        
        try:
            idx = df.index.get_indexer([target_time], method='nearest')[0]
            fri_price = float(df['Close'].iloc[idx])
        except:
            fri_price = float(df['Close'].iloc[0])
        
        if fri_price == 0: return 0.0, "Error", "âšª"

        ret = (now_price - fri_price) / fri_price
        
        if ret > CRYPTO_RED_THRESHOLD:
            return ret, "RED", "ğŸ”´"
        elif ret > CRYPTO_YELLOW_THRESHOLD:
            return ret, "YELLOW", "ğŸŸ¡"
        else:
            return ret, "GREEN", "ğŸŸ¢"

    except Exception:
        return 0.0, "Error", "âšª"

def download_data_in_batches(tickers, period, interval, prepost=False):
    """
    åˆ†æ‰¹ä¸‹è¼‰æ•¸æ“šä»¥é¿å… Timeout
    """
    all_data = []
    total = len(tickers)
    
    for i in range(0, total, BATCH_SIZE):
        batch = tickers[i:i + BATCH_SIZE]
        # ç°¡å–®é€²åº¦é¡¯ç¤º
        # print(f"  Downloading batch {i//BATCH_SIZE + 1}/{(total-1)//BATCH_SIZE + 1} ({len(batch)} tickers)...")
        
        for attempt in range(MAX_RETRIES):
            try:
                # é—œéµä¿®æ­£ï¼šåŠ å…¥ auto_adjust=False, threads=True (åŠ é€Ÿ)
                df = yf.download(
                    batch, 
                    period=period, 
                    interval=interval, 
                    prepost=prepost, 
                    progress=False, 
                    auto_adjust=False,
                    threads=True
                )
                
                # yfinance æœ‰æ™‚å›å‚³ç©º DataFrame
                if not df.empty:
                    all_data.append(df)
                break # æˆåŠŸå‰‡è·³å‡ºé‡è©¦
            except Exception as e:
                if attempt < MAX_RETRIES - 1:
                    time.sleep(1) # ç¨ä½œä¼‘æ¯å¾Œé‡è©¦
                else:
                    print(f"  [Warning] Batch failed: {batch[0]}... {e}")

    if not all_data:
        return pd.DataFrame()
        
    # åˆä½µæ•¸æ“š
    # æ³¨æ„ï¼šyfinance çš„ MultiIndex è¡Œç‚º
    # å¦‚æœåªæœ‰ä¸€å€‹ batch ä¸”åªæœ‰ä¸€æª”è‚¡ç¥¨ï¼Œçµæ§‹å¯èƒ½ä¸åŒï¼Œé€™è£¡å˜—è©¦é€šç”¨çš„ concat
    try:
        # å¦‚æœæ˜¯å¤šå€‹ batchï¼Œéœ€è¦åˆä½µ
        if len(all_data) == 1:
            return all_data[0]
        
        # é‡å° Column é€²è¡Œåˆä½µ (Date index æ˜¯ç›¸åŒçš„)
        # yfinance download å¤šæª”è‚¡ç¥¨æ™‚ï¼ŒColumns æ˜¯ (Price Type, Ticker)
        # æˆ‘å€‘éœ€è¦æ°´å¹³åˆä½µ (axis=1)
        full_df = pd.concat(all_data, axis=1)
        return full_df
    except Exception as e:
        print(f"  [Error] Data merge failed: {e}")
        return pd.DataFrame()

# --- æ›¿æ›éƒ¨åˆ†é–‹å§‹ ---

def get_market_data(tickers):
    print(f"[{datetime.now().strftime('%H:%M:%S')}] æ­£åœ¨ä¸‹è¼‰ {len(tickers)} æª”è‚¡ç¥¨æ•¸æ“š...")
    data_map = {}
    
    # 1. ä¸‹è¼‰æ•¸æ“š (ç‚ºäº†ç°¡åŒ–èˆ‡ç©©å®šï¼Œç›´æ¥æŠ“ 5 å¤©çš„ 1m æ•¸æ“šä¾†æ‰¾æœ€æ–°åƒ¹æ ¼ï¼ŒæŠ“ 1mo æ—¥ç·šæ‰¾æ˜¨æ”¶)
    # ä¸‹è¼‰æ—¥ç·š (Batch)
    try:
        df_daily = download_data_in_batches(tickers, period="1mo", interval="1d")
    except Exception as e:
        print(f"[Error] æ—¥ç·šä¸‹è¼‰å¤±æ•—: {e}")
        return {}

    # ä¸‹è¼‰ç›¤å‰ (Batch)
    try:
        df_intraday = download_data_in_batches(tickers, period="5d", interval="1m", prepost=True)
        if not df_intraday.empty:
            if df_intraday.index.tz is None:
                df_intraday.index = df_intraday.index.tz_localize('UTC').tz_convert('America/New_York')
            else:
                df_intraday.index = df_intraday.index.tz_convert('America/New_York')
    except Exception as e:
        print(f"[Error] åˆ†æ™‚æ•¸æ“šä¸‹è¼‰å¤±æ•—: {e}")
        return {}

    # 3. æ•´åˆæ•¸æ“š
    for ticker in tickers:
        try:
            # --- A. å–å¾— Prev Close (æ˜¨æ”¶) ---
            # è™•ç† MultiIndex æˆ– Single Index
            if isinstance(df_daily.columns, pd.MultiIndex):
                if ticker not in df_daily['Close'].columns:
                    # print(f"  [Skip] {ticker} ç„¡æ—¥ç·šæ•¸æ“š")
                    continue
                c = df_daily['Close'][ticker].dropna()
                h = df_daily['High'][ticker].dropna()
                l = df_daily['Low'][ticker].dropna()
            else:
                if ticker not in df_daily.columns: # é‡å°å–®ä¸€è‚¡ç¥¨çµæ§‹å¯èƒ½ä¸åŒï¼Œé€™è£¡ç°¡åŒ–åˆ¤æ–·
                     # å¦‚æœåªæœ‰ä¸€æª”è‚¡ç¥¨ä¸”æ²’æœ‰ MultiIndexï¼Œcolumns å¯èƒ½ç›´æ¥æ˜¯ 'Close', 'Open'...
                     # ä½† download_data_in_batches è©¦åœ–åˆä½µï¼Œé€šå¸¸æœƒæœ‰ MultiIndex
                     pass
                c = df_daily['Close'].dropna()
                h = df_daily['High'].dropna()
                l = df_daily['Low'].dropna()

            if len(c) < 2: 
                continue

            prev_close = float(c.iloc[-1])
            
            # ATR è¨ˆç®— (14æ—¥)
            tr = h - l 
            atr = tr.rolling(14).mean().iloc[-1]
            atr_pct = atr / prev_close if prev_close > 0 else 0

            # --- B. å–å¾— Current Price (ç¾åƒ¹) ---
            # é‚è¼¯ï¼šå„ªå…ˆæ‰¾ Intraday æœ€å¾Œä¸€ç­†ï¼Œå¦‚æœæ²’æœ‰å‰‡ç”¨æ—¥ç·šæœ€å¾Œä¸€ç­†
            curr_price = np.nan
            pre_high = np.nan
            
            # å˜—è©¦å¾ Intraday ç²å–
            if not df_intraday.empty:
                # è™•ç† Columns
                if isinstance(df_intraday.columns, pd.MultiIndex):
                     if ticker in df_intraday['Close'].columns:
                        series_c = df_intraday['Close'][ticker].dropna()
                        series_h = df_intraday['High'][ticker].dropna() if 'High' in df_intraday.columns else series_c
                        
                        if not series_c.empty:
                            curr_price = float(series_c.iloc[-1])
                            # ç›¤å‰é«˜é»é‚è¼¯ (ç°¡å–®å–æœ€å¾Œä¸€å¤©çš„é«˜é»)
                            last_date = series_c.index[-1].date()
                            today_mask = series_c.index.date == last_date
                            pre_high = float(series_h[today_mask].max())
            
            # å¦‚æœ Intraday æ²’æŠ“åˆ°ï¼Œå›é€€ä½¿ç”¨æ—¥ç·š Close (ä»£è¡¨å°šæœªé–‹ç›¤æˆ–è³‡æ–™å»¶é²)
            if pd.isna(curr_price):
                curr_price = prev_close
                
            # --- Pre-Fade è¨ˆç®— ---
            pre_fade = 0.0
            if pd.notna(pre_high) and pre_high > 0 and pd.notna(curr_price):
                if pre_high > curr_price:
                    pre_fade = (pre_high - curr_price) / pre_high

            data_map[ticker] = {
                'prev_close': prev_close, 
                'curr_price': curr_price, 
                'pre_high': pre_high, 
                'pre_fade': pre_fade, 
                'atr_pct': atr_pct
            }
        except Exception as e:
            # print(f"  [Error] è™•ç† {ticker} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            continue
            
    return data_map

def generate_live_dashboard():
    print(f"\n>>> V6.1 Gap Strategy Dashboard (Holding Monitor)")
    print(f">>> Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("-" * 60)
    
    # 1. è¨­å®šæª”æ¡ˆè·¯å¾‘
    HOLDING_POOL_FILE = '2025_holding_asset_pool.json'

    # 2. è¼‰å…¥æ¸…å–®
    pool_holding = load_tickers_from_json(HOLDING_POOL_FILE)
    pool_toxic = load_tickers_from_json(TOXIC_POOL_FILE)
    pool_sensitive = load_tickers_from_json(SENSITIVE_POOL_FILE)
    
    # ç›´æ¥ç›£æ§æ‰€æœ‰æŒå€‰ï¼Œä¸ä½¿ç”¨é»‘åå–®éæ¿¾
    valid_tickers = pool_holding
    
    print(f"æ¸…å–®æ¦‚æ³:")
    print(f"  - Holding Pool: {len(pool_holding)} æª”")
    
    if not valid_tickers:
        print("[Error] æŒå€‰æ¸…å–®ç‚ºç©ºæˆ–è®€å–å¤±æ•—ã€‚")
        return

    # 3. å–å¾—ç’°å¢ƒç‹€æ…‹
    is_totm, is_pre_holiday, cal_status_str = get_calendar_status()
    eth_ret, eth_status, eth_light = get_crypto_sentiment()
    
    print(f"\n[Market Context]")
    print(f"  ğŸ“… Calendar: {cal_status_str}")
    if eth_status != "Weekday":
        print(f"  ğŸª™ Crypto: ETH {eth_ret*100:+.2f}% {eth_light}")

    # 4. å–å¾—æ•¸æ“š
    market_data = get_market_data(valid_tickers)
    
    if not market_data:
        print("\n[Error] ç„¡æ³•ç²å–å¸‚å ´æ•¸æ“šã€‚")
        return

    report_data = []
    
    for ticker in valid_tickers:
        if ticker not in market_data: 
            # è¨˜éŒ„ç„¡æ•¸æ“šçš„æ¨™çš„
            # report_data.append({'Ticker': ticker, 'Status': 'No Data', 'Score': -99})
            continue
            
        data = market_data[ticker]
        curr_price = data['curr_price']
        prev_close = data['prev_close']
        
        if prev_close <= 0: continue
        
        # è¨ˆç®—æ¼²è·Œå¹…
        gap_pct = (curr_price - prev_close) / prev_close
        
        # [é—œéµä¿®æ”¹] é€™è£¡ç§»é™¤äº† "if gap_pct <= 0: continue"ï¼Œè®“æ‰€æœ‰è‚¡ç¥¨éƒ½èƒ½é¡¯ç¤º
        
        # åˆ†é¡
        if ticker in pool_toxic: cat_code = "T"; category = "Toxic"
        elif ticker in pool_sensitive: cat_code = "S"; category = "Sensitive"
        else: cat_code = "A"; category = "Asset"
            
        atr_pct = data['atr_pct']
        pre_fade = data['pre_fade']
        
        # é–€æª»
        if category in ["Toxic", "Sensitive"]:
            dynamic_threshold = max(DEFAULT_GAP_THRESHOLD, 0.3 * atr_pct)
        else:
            dynamic_threshold = DEFAULT_GAP_THRESHOLD

        trigger_price = prev_close * (1 + dynamic_threshold)

        # ç‹€æ…‹åˆ¤æ–·
        status = "Watching"
        score = 0
        
        if gap_pct > dynamic_threshold:
            status = "ğŸ”´ GAP UP"
            score = 2
            # ç°¡å–®çš„éæ¿¾é‚è¼¯é¡¯ç¤º
            if category == "Asset" and (is_totm or is_pre_holiday): status += " (Skip)"
        elif gap_pct < -0.02:
            status = "ğŸŸ¢ GAP DOWN"
            score = -1
        elif abs(gap_pct) <= 0.001:
            status = "Flat"
            
        report_data.append({
            'Ticker': ticker, 'Cat': cat_code,
            'Gap%': gap_pct, 'Thres%': dynamic_threshold,
            'Fade%': pre_fade, 'ATR%': atr_pct,
            'Price': curr_price, 'TrigPx': trigger_price,
            'Status': status, 'Score': score
        })
            
    # 5. è¼¸å‡ºå ±è¡¨
    if not report_data:
        print("\nç„¡æ•¸æ“šå¯é¡¯ç¤ºã€‚")
        return

    df = pd.DataFrame(report_data)
    # ä¾ç…§æ¼²è·Œå¹…æ’åº
    df.sort_values(by=['Gap%'], ascending=False, inplace=True)
    
    print("\n" + "="*105) 
    print(f"{'Ticker':<6} {'Cat':<3} {'Gap%':>7} {'Thres%':>7} {'Fade%':>7} {'ATR%':>6} {'Price':>8} {'TrigPx':>8} {'Status':<20}")
    print("-" * 105)
    
    for _, row in df.iterrows():
        # è™•ç†å¯èƒ½çš„ NaN
        gap_val = row['Gap%'] if pd.notna(row['Gap%']) else 0
        fade_val = row['Fade%'] if pd.notna(row['Fade%']) else 0
        
        mark = "  "
        if gap_val > row['Thres%']: mark = ">>"
        
        print(f"{mark} {row['Ticker']:<6} {row['Cat']:<3} "
              f"{gap_val*100:>6.2f}% {row['Thres%']*100:>6.2f}% "
              f"{fade_val*100:>6.2f}% {row['ATR%']*100:>5.1f}% "
              f"{row['Price']:>8.2f} {row['TrigPx']:>8.2f} {row['Status']:<20}")
    print("="*105)

    outfile = os.path.join(OUTPUT_DIR, f'holding_monitor_{datetime.now().strftime("%Y%m%d")}.csv')
    df.to_csv(outfile, index=False)
    print(f"\n[Saved] {outfile}")

# --- æ›¿æ›éƒ¨åˆ†çµæŸ ---

if __name__ == '__main__':
    try:
        generate_live_dashboard()
    except KeyboardInterrupt:
        print("\nStopped.")